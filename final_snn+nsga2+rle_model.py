# -*- coding: utf-8 -*-
"""final SNN+NSGA2+RLE model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1myjZBkTAHTz5b2bmPXObZ4o8cVSmH2KA
"""

!git clone https://github.com/Project-Platypus/Platypus.git

cd Platypus/

!python setup.py develop

# -*- coding: utf-8 -*-
"""
Created on Sat Jul 29 01:33:01 2017

@author: Shivendra
"""

#librariesfor the main code
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils
from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping
from keras.models import load_model
from keras import regularizers
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from matplotlib import pyplot
from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestRegressor
from sklearn import preprocessing
from sklearn.metrics import accuracy_score
from sklearn.metrics import average_precision_score
from sklearn.metrics import f1_score

from math import *
import math
from matplotlib import pyplot as plotter

#uploading training
from google.colab import files
uploaded = files.upload()

from platypus import NSGAII, Problem, Real

global ctr
ctr=0
def getAcc(x):
  global ctr
  ctr=ctr+1
  print ("##########CTR###########################",ctr)
  #x[0]---variable
  #x[1]---hidden layers
  #x[2]---train ratio
  x[0]=np.int(x[0])
  x[1]=int(x[1])
  print (x[0], x[1])
  dataset=np.loadtxt(r"train_cardio.csv",delimiter=",")
  X=dataset[:,0:21]
  scaler = preprocessing.StandardScaler().fit(X)
  X=scaler.transform(X)
  Y_test=np.array(dataset[:,21],dtype='int32')
  Y=np_utils.to_categorical(dataset[:,21])
  
  size=np.size(X,0)-5
  train_ratio=np.int(np.floor(x[2]*size))
  test_ratio=np.int(np.floor((1-x[2])/2*size))
  print(train_ratio,test_ratio)
  
  crossX=X[train_ratio+test_ratio:,:]
  testX=X[train_ratio:train_ratio+test_ratio,:]
  X=X[0:train_ratio,:]

  crossY=Y[train_ratio+test_ratio:,:]
  testY=Y_test[train_ratio: train_ratio+test_ratio]
  Y=Y[0:train_ratio,:]

  print("preprocessing")
  rfe = RFE(RandomForestRegressor(n_estimators=5, random_state=1), X)
  fit = rfe.fit(X[0:np.int(train_ratio/2)],Y_test[0:np.int(train_ratio/2)])
  selected=fit.get_support(indices=True)
  X=X[:,selected]
  testX=testX[:,selected]
  crossX=crossX[:,selected]
  print(X.shape)

###############
#parameters
###############

  batch=64
  input_layer=int(x[0])
  #input_layer=52
  output_layer=4
  hiddenLayer1=int(x[1])
  hiddenLayer2=50
  activation_hidden='relu'
  activation_output='softmax'
  optimizer='adam'
  iteration=1500


#####################
#defining the model
#####################
  model=Sequential()

#######################
#non-regularised
#######################

  model.add(Dense(hiddenLayer1,input_dim=(input_layer),activation=activation_hidden,kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.5, seed=None)))
#model.add(Dense(hiddenLayer2,activation=activation_hidden,kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.5, seed=None)))
  model.add(Dense(output_layer,activation=activation_output,kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.5, seed=None)))

##########################
#Compiling model
###########################
  model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])
# model=load_model('F:\Study\MinorP\h5file\sept_Batch_checking'+str(arr[i])+'.h5')
  model_checkpoint = [EarlyStopping(monitor='val_loss', patience=200,verbose=0)]

  #####Fit model#################################
  history=model.fit(X, Y, epochs=iteration, batch_size=batch,validation_data=(crossX,crossY),callbacks=model_checkpoint)
  
  
  classes=4
  test_case=np.zeros(classes)
  predicted_correct=np.zeros(classes)
  result=np.zeros(classes,dtype=float)
  prediction=model.predict(testX)


  for i in range (np.size(testX,0)):
    test_case[testY[i]]+=1
    if np.argmax(prediction[i]) == testY[i] :       
        predicted_correct[testY[i]]+=1     
  print("test_case",test_case)
  print("predicted_correct",predicted_correct)
  for i in range (np.size(predicted_correct,0)):
    result[i]=float(predicted_correct[i]*100)/test_case[i]
  Acc=0
  print ("number of variables used =========>",x[0])
  prediction_col=np.zeros((testY.shape))
  for l in range(np.size(testX,0)):
    prediction_col[l]=np.argmax(prediction[l])
  Acc=accuracy_score(testY,prediction_col)
  print("Overall accuracy",Acc)
  print("f1 weighted score",f1_score(testY, prediction_col, average='weighted'))
  return [1/(Acc),x[0]]

problem = Problem(3, 2) #number of variable, numebr of objectives

#bounds
problem.types[0] = Real(1,5)
problem.types[1] = Real(2, 10)
problem.types[2] = Real(0.4,0.8)
problem.function = getAcc

algorithm = NSGAII(problem,20) #population size 20
algorithm.run(20)# genertion 40
print (algorithm.result)

import matplotlib.pyplot as plt
plt.scatter([s.objectives[0] for s in algorithm.result], 
            [s.objectives[1] for s in algorithm.result])

plt.xlabel("$f_1(x)$")
plt.ylabel("$f_2(x)$")
plt.show()